{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "428ee493",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "import fraud_detection.viz.plots  as viz\n",
    "import fraud_detection.analysis.eda as eda\n",
    "from fraud_detection.data.loader import DataHandler\n",
    "from fraud_detection.core.settings import settings\n",
    "from fraud_detection.data.cleaning import DataCleaning\n",
    "from fraud_detection.features.preprocessing import build_preprocessing_pipeline\n",
    "from imblearn.over_sampling import SMOTE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31b4fed3",
   "metadata": {},
   "source": [
    "- Data I/O"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c29d4af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Card data \n",
    "df = DataHandler.from_registry(\"DATA\", \"raw_dir\", \"creditcard.csv\").load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "333f326a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55cfb9fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Class distribution\n",
    "class_counts = df['class'].value_counts()\n",
    "class_pct = df['class'].value_counts(normalize=True) * 100\n",
    "\n",
    "print(\"Class Distribution:\")\n",
    "print(f\"  Non-Fraud (0): {class_counts[0]:,} ({class_pct[0]:.2f}%)\")\n",
    "print(f\"  Fraud (1):     {class_counts[1]:,} ({class_pct[1]:.2f}%)\")\n",
    "print(f\"\\nImbalance Ratio: 1:{class_counts[0]/class_counts[1]:.1f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25ea9191",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 1. Check Class Imbalance\n",
    "viz.plot_class_distribution(class_counts)\n",
    "\n",
    "\n",
    "# 2. Compare Numerical Distributions (Age and Purchase Value)\n",
    "viz.plot_numeric_distribution(df, 'age')\n",
    "viz.plot_numeric_distribution(df, 'purchase_value')\n",
    "\n",
    "# 3. Deep dive into Purchase Value Outliers\n",
    "viz.plot_numeric_by_class(df, 'purchase_value')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5396a42",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_with_country contains 'country' and 'class'\n",
    "country_stats = eda.get_country_fraud_stats(df)\n",
    "\n",
    "top_count = eda.get_top_countries_by_fraud_count(country_stats, top_n=10)\n",
    "top_rate = eda.get_top_countries_by_fraud_rate(\n",
    "    country_stats, min_transactions=50, top_n=10)\n",
    "country_stats\n",
    "overall_rate = df['class'].mean() * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00396b68",
   "metadata": {},
   "outputs": [],
   "source": [
    "top_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c6123f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "top_rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d35965e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. Geographic Analysis (Volume vs Risk)\n",
    "viz.plot_country_transactions(country_stats, top_n=15)\n",
    "viz.plot_country_fraud_overview(\n",
    "    country_stats=country_stats,\n",
    "    country_stats_filtered=top_rate,\n",
    "    overall_rate=overall_rate,\n",
    "    top_n=10,\n",
    "    min_transactions=200,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ed99d9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_features = add_fraud_features(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d844837",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa4998ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Daily fraud trends\n",
    "viz.plot_fraud_over_time(df_features, time_col='purchase_time', freq='D')\n",
    "\n",
    "# Weekly fraud trends\n",
    "viz.plot_fraud_over_time(df_features, time_col='purchase_time', freq='W')\n",
    "\n",
    "# Hour-of-day and day-of-week patterns\n",
    "viz.plot_fraud_by_hour_day(df_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8684a28c",
   "metadata": {},
   "source": [
    "### Feature Engineering and Sampling Imbalanced data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44e133a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "FEATURES = settings.get(\"features\")\n",
    "\n",
    "TARGET = FEATURES[\"target\"]\n",
    "NUM_COLS = FEATURES[\"numeric\"]\n",
    "CAT_COLS = FEATURES[\"categorical\"]\n",
    "# -----------------------------\n",
    "# 1. Split features and target\n",
    "# -----------------------------\n",
    "X = df_features.drop(columns=[TARGET])\n",
    "y = df_features[TARGET]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, stratify=y, random_state=42\n",
    ")\n",
    "\n",
    "# -----------------------------\n",
    "# 2. Build and apply feature pipeline\n",
    "# -----------------------------\n",
    "preprocessor = build_preprocessing_pipeline(NUM_COLS, CAT_COLS)\n",
    "\n",
    "X_train_transformed = preprocessor.fit_transform(X_train)\n",
    "X_test_transformed = preprocessor.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8d54e05",
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2de91eae",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n--- Class Distribution BEFORE SMOTE (Train) ---\")\n",
    "print(y_train.value_counts(normalize=True).map(\"{:.2%}\".format))\n",
    "\n",
    "# -----------------------------\n",
    "# 3. Extract feature names (for DataFrame / saving)\n",
    "# -----------------------------\n",
    "feature_names = preprocessor.get_feature_names_out()\n",
    "X_train_df = pd.DataFrame(X_train_transformed, columns=feature_names)\n",
    "X_train_df[TARGET] = y_train.reset_index(drop=True)\n",
    "\n",
    "X_test_df = pd.DataFrame(X_test_transformed, columns=feature_names)\n",
    "X_test_df[TARGET] = y_test.reset_index(drop=True)\n",
    "\n",
    "\n",
    "# -----------------------------\n",
    "# 4. Apply SMOTE (only on training set)\n",
    "# -----------------------------\n",
    "\n",
    "# adjust ratio if needed\n",
    "smote = SMOTE(random_state=42)\n",
    "X_train_resampled, y_train_resampled = smote.fit_resample(\n",
    "    X_train_transformed, y_train\n",
    ")\n",
    "\n",
    "# Save to DataFrame for consistency\n",
    "X_train_res_df = pd.DataFrame(X_train_resampled, columns=feature_names)\n",
    "X_train_res_df[TARGET] = y_train_resampled.reset_index(drop=True)\n",
    "\n",
    "print(\"\\n--- Class Distribution AFTER SMOTE ---\")\n",
    "print(y_train_resampled.value_counts(normalize=True).map(\"{:.2%}\".format))\n",
    "\n",
    "# -----------------------------\n",
    "# 5. Save datasets \n",
    "# -----------------------------\n",
    "\n",
    "train_original_df = pd.DataFrame(X_train_transformed, columns=feature_names)\n",
    "train_original_df[TARGET] = y_train.reset_index(drop=True)\n",
    "\n",
    "train_original_handler = DataHandler.from_registry(\n",
    "    section=\"DATA\",\n",
    "    path_key=\"processed_dir\",\n",
    "    filename=\"train_original.parquet\"\n",
    ").save(train_original_df)\n",
    "\n",
    "\n",
    "DataHandler.from_registry(\n",
    "    section=\"DATA\",\n",
    "    path_key=\"processed_dir\",\n",
    "    filename=\"train_resampled.parquet\"\n",
    ").save(X_train_res_df)\n",
    "\n",
    "\n",
    "DataHandler.from_registry(\n",
    "    section=\"DATA\",\n",
    "    path_key=\"processed_dir\",\n",
    "    filename=\"test_original.parquet\"\n",
    "    \n",
    ").save(X_test_df)\n",
    "\n",
    "print(\"[INFO] Preprocessing and SMOTE complete. Data saved.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
